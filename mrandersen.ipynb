{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# COMP90051 Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit. These are the only imports permitted.\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Implement Îµ-Greedy and UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAB(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class that represents a multi-armed bandit (MAB)\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def play(self, tround, context):\n",
    "        \"\"\"\n",
    "        Play a round\n",
    "        \n",
    "        Arguments\n",
    "        =========\n",
    "        tround : int\n",
    "            positive integer identifying the round\n",
    "        \n",
    "        context : 1D float array, shape (self.ndims * self.narms), optional\n",
    "            context given to the arms\n",
    "        \n",
    "        Returns\n",
    "        =======\n",
    "        arm : int\n",
    "            the positive integer arm id for this round\n",
    "        \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self, arm, reward, context):\n",
    "        \"\"\"\n",
    "        Updates the internal state of the MAB after a play\n",
    "        \n",
    "        Arguments\n",
    "        =========\n",
    "        arm : int\n",
    "            a positive integer arm id in {1, ..., self.narms}\n",
    "        \n",
    "        reward : float\n",
    "            reward received from arm\n",
    "        \n",
    "        context : 1D float array, shape (self.ndims * self.narms), optional\n",
    "            context given to arms\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsGreedy(MAB):\n",
    "    \"\"\"\n",
    "    Epsilon-Greedy multi-armed bandit\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "    narms : int\n",
    "        number of arms\n",
    "\n",
    "    epsilon : float\n",
    "        explore probability\n",
    "\n",
    "    Q0 : float, optional\n",
    "        initial value for the arms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, narms, epsilon, Q0=np.inf):\n",
    "        self.narms = narms\n",
    "        self.epsilon = epsilon\n",
    "        self.Q0 = Q0\n",
    "        self.pullsNum = np.zeros(narms)\n",
    "        self.values = np.full(narms, Q0)\n",
    "        \n",
    "    def play(self, tround, context=None):\n",
    "        # tround not used in this implementation of MAB\n",
    "        rand = np.random.random()\n",
    "        # if rand < epsilon, pick random arm (explore), otherwise pick best arm (exploit) (with random tiebreak)\n",
    "        if rand < self.epsilon:\n",
    "            return np.random.randint(self.narms)\n",
    "        else:\n",
    "            maxValue = max(self.values)\n",
    "            bestArms = [i for i, value in enumerate(self.values) if value == maxValue]\n",
    "            return np.random.choice(bestArms)\n",
    "        \n",
    "    def update(self, arm, reward, context=None):\n",
    "        if self.values[arm] == self.Q0:\n",
    "            self.values[arm] = reward\n",
    "        else:\n",
    "            value = (self.values[arm] * self.pullsNum[arm] + reward) / (self.pullsNum[arm] + 1)\n",
    "            self.values[arm] = value\n",
    "        self.pullsNum[arm] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliArm:\n",
    "    def __init__(self):\n",
    "        self.p = np.random.random()\n",
    "    \n",
    "    def pull(self):\n",
    "        return int(np.random.random() < self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.024720759901472822,\n",
       " 0.992402994515029,\n",
       " 0.07314369305962387,\n",
       " 0.014176883428488884,\n",
       " 0.7831487936728914,\n",
       " 0.4550515167074527,\n",
       " 0.6790586426195484,\n",
       " 0.6260793137619918,\n",
       " 0.8546199225486811,\n",
       " 0.5842458967422974]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulliArms = [BernoulliArm() for i in range(10)]\n",
    "[a.p for a in bernoulliArms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accumulated_rewards 1889\n",
      "max reward possible 1984.805989030058\n",
      "regret 95.80598903005807\n"
     ]
    }
   ],
   "source": [
    "epsGreedy = EpsGreedy(10, 0.1)\n",
    "accumulated_rewards = 0\n",
    "pulls_num = 0\n",
    "running_avg_rewards = [0] * 2000\n",
    "# print(epsGreedy.values)\n",
    "for i in range(0, 2000):\n",
    "    arm = epsGreedy.play(None)\n",
    "    reward = bernoulliArms[arm].pull()\n",
    "    accumulated_rewards += reward\n",
    "    epsGreedy.update(arm, reward)\n",
    "    \n",
    "    pulls_num += 1\n",
    "    running_avg_rewards[i] = accumulated_rewards / pulls_num\n",
    "    \n",
    "#     if (i % 100 == 0):\n",
    "#         print(\"-\")\n",
    "#         print(accumulated_rewards)\n",
    "#         print(epsGreedy.values)\n",
    "#         print(\"-\")\n",
    "\n",
    "print(\"accumulated_rewards \" + str(accumulated_rewards))\n",
    "# print(epsGreedy.values)\n",
    "print(\"max reward possible \" + str(max([b.p for b in bernoulliArms])*2000))\n",
    "print(\"regret \" + str(max([b.p for b in bernoulliArms]) * 2000 - accumulated_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(running_avg_rewards)\n",
    "plt.ylabel(\"Average Rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB(MAB):\n",
    "    \"\"\"\n",
    "    Upper Confidence Bound (UCB) multi-armed bandit\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "    narms : int\n",
    "        number of arms\n",
    "\n",
    "    rho : float\n",
    "        positive real explore-exploit parameter\n",
    "\n",
    "    Q0 : float, optional\n",
    "        initial value for the arms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, narms, rho, Q0=np.inf):\n",
    "        self.narms = narms\n",
    "        self.rho = rho\n",
    "        self.Q0 = Q0\n",
    "        self.pullsNum = np.zeros(narms)\n",
    "        self.values = np.full(narms, Q0)\n",
    "    \n",
    "    def play(self, tround, context=None):\n",
    "        # compute the sum of average reward and confidence interval for each arm\n",
    "        estimatedValues = [0] * self.narms\n",
    "        for i in range(self.narms):\n",
    "            avg_arm_value = self.values[i]\n",
    "            if avg_arm_value == self.Q0:\n",
    "                estimatedValues[i] = self.Q0\n",
    "            else:\n",
    "                confidence_interval = np.sqrt((self.rho * np.log(tround)) / self.pullsNum[i])\n",
    "                estimatedValues[i] = avg_arm_value + confidence_interval\n",
    "        \n",
    "        # choose randomly between arms with max sum of avg reward and confidence interval\n",
    "        maxValue = max(estimatedValues)\n",
    "        bestArms = [i for i, value in enumerate(estimatedValues) if value == maxValue]\n",
    "        return np.random.choice(bestArms)\n",
    "        \n",
    "    def update(self, arm, reward, context=None):\n",
    "        if self.values[arm] == self.Q0:\n",
    "            self.values[arm] = reward\n",
    "        else:\n",
    "            value = (self.values[arm] * self.pullsNum[arm] + reward) / (self.pullsNum[arm] + 1)\n",
    "            self.values[arm] = value\n",
    "        self.pullsNum[arm] += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23798591010405146,\n",
       " 0.9676724672609208,\n",
       " 0.9922745092488273,\n",
       " 0.2587785147848032,\n",
       " 0.1503146620760335,\n",
       " 0.7787391640752427,\n",
       " 0.1911878096149665,\n",
       " 0.7602783662788827,\n",
       " 0.009288577294310318,\n",
       " 0.32449256348675337]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulliArms = [BernoulliArm() for i in range(10)]\n",
    "[a.p for a in bernoulliArms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accumulated_rewards 1829\n",
      "[0.34615385 0.96788321 0.99405352 0.07142857 0.16666667 0.74782609\n",
      " 0.07142857 0.67532468 0.07142857 0.35714286]\n",
      "max reward possible 1984.5490184976547\n",
      "regret 155.54901849765474\n"
     ]
    }
   ],
   "source": [
    "mab = UCB(10, 2)\n",
    "accumulated_rewards = 0\n",
    "# print(epsGreedy.values)\n",
    "for i in range(0, 2000):\n",
    "    arm = mab.play(i)\n",
    "    reward = bernoulliArms[arm].pull()\n",
    "    accumulated_rewards += reward\n",
    "    mab.update(arm, reward)\n",
    "\n",
    "#     if (i % 100 == 0):\n",
    "#         print(\"-\")\n",
    "#         print(accumulated_rewards)\n",
    "#         print(epsGreedy.values)\n",
    "#         print(\"-\")\n",
    "\n",
    "print(\"accumulated_rewards \" + str(accumulated_rewards))\n",
    "print(mab.values)\n",
    "maxReward = max([b.p for b in bernoulliArms])*2000\n",
    "print(\"max reward possible \" + str(maxReward))\n",
    "print(\"regret \" + str(maxReward - accumulated_rewards))\n",
    "\n",
    "#[a.p for a in bernoulliArms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Off-Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offlineEvaluate(mab, arms, rewards, contexts, nrounds=None):\n",
    "    \"\"\"\n",
    "    Offline evaluation of a multi-armed bandit\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    mab : instance of MAB\n",
    "    \n",
    "    arms : 1D int array, shape (nevents,) \n",
    "        integer arm id for each event\n",
    "    \n",
    "    rewards : 1D float array, shape (nevents,)\n",
    "        reward received for each event\n",
    "    \n",
    "    contexts : 2D float array, shape (nevents, mab.narms*nfeatures)\n",
    "        contexts presented to the arms (stacked horizontally) \n",
    "        for each event.\n",
    "        \n",
    "    nrounds : int, optional\n",
    "        number of matching events to evaluate `mab` on.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    out : 1D float array\n",
    "        rewards for the matching events\n",
    "    \"\"\"\n",
    "    round_rewards = []\n",
    "    stream_iterator = 0\n",
    "    \n",
    "    if nrounds == None:\n",
    "        return round_rewards\n",
    "    \n",
    "    for t in range(nrounds):\n",
    "        while True:\n",
    "            if stream_iterator >= len(arms):\n",
    "                print(stream_iterator)\n",
    "                return round_rewards\n",
    "            if mab.play(t) == int(arms[stream_iterator]) - 1: # -1 because the arms from data is one indexed\n",
    "                break\n",
    "            else:\n",
    "                stream_iterator += 1\n",
    "        \n",
    "        round_rewards.append(rewards[stream_iterator])\n",
    "        mab.update(int(arms[stream_iterator]) - 1, rewards[stream_iterator], contexts[stream_iterator])\n",
    "        stream_iterator += 1\n",
    "    \n",
    "    #print(stream_iterator)\n",
    "    return round_rewards\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"dataset.txt\")\n",
    "arms = data[:,0]\n",
    "rewards = data[:,1]\n",
    "contexts = data[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EpsGreedy average reward 0.23\n",
      "[ 12. 523. 174.   5.   6.   5.   6.   4.  61.   4.]\n",
      "[0.         0.28871893 0.14367816 0.         0.         0.\n",
      " 0.         0.         0.13114754 0.        ]\n"
     ]
    }
   ],
   "source": [
    "mab = EpsGreedy(10, 0.05)\n",
    "results_EpsGreedy = offlineEvaluate(mab, arms, rewards, contexts, 800)\n",
    "print('EpsGreedy average reward', np.mean(results_EpsGreedy))\n",
    "print(mab.pullsNum)\n",
    "print(mab.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCB average reward 0.16375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.25615764, 0.14285714, 0.025     , 0.07692308,\n",
       "       0.08928571, 0.22307692, 0.        , 0.21212121, 0.025     ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mab = UCB(10, 1.0)\n",
    "results_UCB = offlineEvaluate(mab, arms, rewards, contexts, 800)\n",
    "print('UCB average reward', np.mean(results_UCB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contextual Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-16-0c2e2d1f0e69>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-0c2e2d1f0e69>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    def play(self, tround, context):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class LinUCB(MAB):\n",
    "    \"\"\"\n",
    "    Contextual multi-armed bandit (LinUCB)\n",
    "\n",
    "    Arguments\n",
    "    =========\n",
    "    narms : int\n",
    "        number of arms\n",
    "\n",
    "    ndims : int\n",
    "        number of dimensions for each arm's context\n",
    "\n",
    "    alpha : float\n",
    "        positive real explore-exploit parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, narms, ndims, alpha):\n",
    "        \n",
    "        \n",
    "    def play(self, tround, context):\n",
    "        \n",
    "    \n",
    "    def update(self, arm, reward, context):\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab = LinUCB(10, 10, 1.0)\n",
    "results_LinUCB = offlineEvaluate(mab, arms, rewards, contexts, 800)\n",
    "print('LinUCB average reward', np.mean(results_LinUCB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "### 4.A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KernelUCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit. Special import for this section.\n",
    "from sklearn.metrics.pairwise import rbf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelUCB(MAB):\n",
    "    \"\"\"\n",
    "    Kernelised contextual multi-armed bandit (Kernelised LinUCB)\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    narms : int\n",
    "        number of arms\n",
    "\n",
    "    ndims : int\n",
    "        number of dimensions for each arm's context\n",
    "\n",
    "    gamma : float\n",
    "        positive real explore-exploit parameter\n",
    "    \n",
    "    eta : float\n",
    "        positive real explore-exploit parameter\n",
    "    \n",
    "    kern : callable\n",
    "        a kernel function from sklearn.metrics.pairwise\n",
    "    \"\"\"\n",
    "    def __init__(self, narms, ndims, gamma, eta, kern):\n",
    "        \n",
    "    \n",
    "    def play(self, tround, context):\n",
    "        \n",
    "    \n",
    "    def update(self, arm, reward, context):\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
